{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.layers import Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(1337)\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "noise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\n",
    "x_train_noisy = x_train + noise\n",
    "noise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\n",
    "x_test_noisy = x_test + noise\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 32\n",
    "kernel_size = 3\n",
    "latent_dim = 16\n",
    "layer_filters = [32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"encoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nencoder_input (InputLayer)   (None, 28, 28, 1)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 14, 14, 32)        320       \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 7, 7, 64)          18496     \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 3136)              0         \n_________________________________________________________________\nlatent_vector (Dense)        (None, 16)                50192     \n=================================================================\nTotal params: 69,008\nTrainable params: 69,008\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "\n",
    "for filters in layer_filters:\n",
    "    x = Conv2D(filters=filters,kernel_size=kernel_size,strides=2,activation='relu',padding='same')(x)\n",
    "shape = K.int_shape(x)\n",
    "x = Flatten()(x)\n",
    "latent = Dense(latent_dim, name='latent_vector')(x)\n",
    "encoder = Model(inputs, latent, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndecoder_input (InputLayer)   (None, 16)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 3136)              53312     \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 7, 7, 64)          0         \n_________________________________________________________________\nconv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        36928     \n_________________________________________________________________\nconv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        18464     \n_________________________________________________________________\ndecoder_output (Conv2DTransp (None, 28, 28, 1)         289       \n=================================================================\nTotal params: 108,993\nTrainable params: 108,993\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"autoencoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nencoder_input (InputLayer)   (None, 28, 28, 1)         0         \n_________________________________________________________________\nencoder (Model)              (None, 16)                69008     \n_________________________________________________________________\ndecoder (Model)              (None, 28, 28, 1)         108993    \n=================================================================\nTotal params: 178,001\nTrainable params: 178,001\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\n  864/60000 [..............................] - ETA: 1:33 - loss: 0.1443"
    }
   ],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "for filters in layer_filters[::-1]:\n",
    "    x = Conv2DTranspose(filters=filters,kernel_size=kernel_size,strides=2,activation='relu',padding='same')(x)\n",
    "outputs = Conv2DTranspose(filters=1,kernel_size=kernel_size,padding='same',activation='sigmoid',name='decoder_output')(x)\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(loss='mse', optimizer='adam')\n",
    "autoencoder.fit(x_train_noisy,x_train,validation_data=(x_test_noisy, x_test),epochs=10,batch_size=batch_size)\n",
    "x_decoded = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 3, 9\n",
    "num = rows * cols\n",
    "imgs = np.concatenate([x_test[:num], x_test_noisy[:num], x_decoded[:num]])\n",
    "imgs = imgs.reshape((rows * 3, cols, image_size, image_size))\n",
    "imgs = np.vstack(np.split(imgs, rows, axis=1))\n",
    "imgs = imgs.reshape((rows * 3, -1, image_size, image_size))\n",
    "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
    "imgs = (imgs * 255).astype(np.uint8)\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('Original images: top rows, '\n",
    "          'Corrupted Input: middle rows, '\n",
    "          'Denoised Input:  third rows')\n",
    "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
    "Image.fromarray(imgs).save('corrupted_and_denoised.png')\n",
    "plt.show()"
   ]
  }
 ]
}